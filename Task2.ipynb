{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   space_group  MagpieData minimum Number  MagpieData maximum Number  \\\n",
      "4           62                       14.0                       44.0   \n",
      "2          221                       14.0                       76.0   \n",
      "0          124                       14.0                       41.0   \n",
      "3           63                       31.0                       31.0   \n",
      "\n",
      "   MagpieData range Number  MagpieData mean Number  MagpieData avg_dev Number  \\\n",
      "4                     30.0               34.000000                  13.333333   \n",
      "2                     62.0               45.000000                  31.000000   \n",
      "0                     27.0               34.166667                   9.111111   \n",
      "3                      0.0               31.000000                   0.000000   \n",
      "\n",
      "   MagpieData mode Number  MagpieData minimum MendeleevNumber  \\\n",
      "4                    44.0                                56.0   \n",
      "2                    14.0                                57.0   \n",
      "0                    41.0                                47.0   \n",
      "3                    31.0                                74.0   \n",
      "\n",
      "   MagpieData maximum MendeleevNumber  MagpieData range MendeleevNumber  ...  \\\n",
      "4                                78.0                              22.0  ...   \n",
      "2                                78.0                              21.0  ...   \n",
      "0                                78.0                              31.0  ...   \n",
      "3                                74.0                               0.0  ...   \n",
      "\n",
      "   MagpieData mean SpaceGroupNumber  MagpieData avg_dev SpaceGroupNumber  \\\n",
      "4                        205.000000                            14.666667   \n",
      "2                        210.500000                            16.500000   \n",
      "0                        222.833333                             9.611111   \n",
      "3                         64.000000                             0.000000   \n",
      "\n",
      "   MagpieData mode SpaceGroupNumber  minimum oxidation state  \\\n",
      "4                             194.0                       -4   \n",
      "2                             194.0                       -4   \n",
      "0                             229.0                        0   \n",
      "3                              64.0                        0   \n",
      "\n",
      "   maximum oxidation state  range oxidation state  std_dev oxidation state  \\\n",
      "4                        2                      6                 4.242641   \n",
      "2                        4                      8                 5.656854   \n",
      "0                        0                      0                 0.000000   \n",
      "3                        0                      0                 0.000000   \n",
      "\n",
      "     density        vpa  packing fraction  \n",
      "4   9.539514  13.358418          0.598395  \n",
      "2  13.968635  12.976265          0.569426  \n",
      "0   7.834556  16.201654          0.688834  \n",
      "3   6.036267  19.180359          0.479802  \n",
      "\n",
      "[4 rows x 140 columns]    space_group  MagpieData minimum Number  MagpieData maximum Number  \\\n",
      "1          164                       13.0                       27.0   \n",
      "\n",
      "   MagpieData range Number  MagpieData mean Number  MagpieData avg_dev Number  \\\n",
      "1                     14.0                    19.0                        6.4   \n",
      "\n",
      "   MagpieData mode Number  MagpieData minimum MendeleevNumber  \\\n",
      "1                    14.0                                58.0   \n",
      "\n",
      "   MagpieData maximum MendeleevNumber  MagpieData range MendeleevNumber  ...  \\\n",
      "1                                78.0                              20.0  ...   \n",
      "\n",
      "   MagpieData mean SpaceGroupNumber  MagpieData avg_dev SpaceGroupNumber  \\\n",
      "1                             213.4                                15.52   \n",
      "\n",
      "   MagpieData mode SpaceGroupNumber  minimum oxidation state  \\\n",
      "1                             194.0                       -4   \n",
      "\n",
      "   maximum oxidation state  range oxidation state  std_dev oxidation state  \\\n",
      "1                        3                      7                 3.872983   \n",
      "\n",
      "    density        vpa  packing fraction  \n",
      "1  5.384968  12.397466          0.644386  \n",
      "\n",
      "[1 rows x 140 columns]         K_VRH\n",
      "4  256.768081\n",
      "2  295.077545\n",
      "0  194.268884\n",
      "3   49.130670         K_VRH\n",
      "1  175.449907\n"
     ]
    }
   ],
   "source": [
    "from json import dump,load\n",
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "                             RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "X = read_csv('dummydata.csv')\n",
    "y = read_csv('dummytarget.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train, X_test, y_train, y_test)\n",
    "#print(X_train.columns, y_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test standardized is [[ 0.71740383 -0.71319739 -1.24502525 -0.71651075 -3.20127747 -0.61787331\n",
      "  -1.57912152 -0.05123155  0.57735027  0.13193985  0.5913391   0.32537216\n",
      "  -0.05123155 -0.63858088 -1.19160056 -0.74558373 -2.78875495 -0.6365947\n",
      "  -1.58304416 -0.67994008 -0.41197454 -0.11339099 -0.33845814 -0.57190192\n",
      "  -0.15356867  0.17407766  0.57735027 -0.07647191  0.71728888  0.08149481\n",
      "   0.17407766 -0.57735027 -1.41421356 -0.6882472  -4.57238085 -0.52934897\n",
      "  -1.50755672 -0.57735027 -1.2080809  -0.79747079 -1.41031496 -0.8611614\n",
      "  -1.19887761 -1.57077449 -0.72686751  0.50037023 -0.48093388 -0.2241944\n",
      "   0.01159114  1.          0.         -1.          1.         -1.\n",
      "   1.         -0.57735027  0.57735027  0.57735027  0.90453403  0.48571429\n",
      "  -0.57735027 -0.57735027 -0.33333333  0.68599434 -0.941675    1.17213184\n",
      "  -1.41904849  0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.         -0.83395039 -0.72428597 -0.11095901 -1.07431333 -0.12069857\n",
      "  -1.          0.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.57735027  1.73205081  1.15470054  0.21132493  1.10285714\n",
      "  -0.57735027  0.         -0.11547005 -0.11547005 -0.57961273  0.13063945\n",
      "  -0.90453403  0.          0.          0.          0.          0.\n",
      "   0.         -1.41421356  0.          0.57735027 -1.18401347  0.37280332\n",
      "  -1.63299316 -1.27829167  0.57735027  1.17186491 -1.60402707  1.64932554\n",
      "  -2.48466392  0.          0.57735027  0.57735027  0.80498447  0.89714286\n",
      "   0.          0.          1.73205081  1.73205081  4.96521232  3.41329479\n",
      "   0.          0.57735027  0.56790565  0.53078768  0.58408182  0.83164162\n",
      "   0.37707023 -1.          0.90453403  0.98019606  0.55373392 -1.34548935\n",
      "  -1.21334092  0.80782236]] train standardized is [[-0.85625618 -0.57735027 -0.23714767  0.01137319 -0.38352713 -0.00246558\n",
      "   0.98161608 -0.25615776  0.57735027  0.30785965 -0.18945816  0.55306799\n",
      "  -0.25615776 -0.57735027 -0.27114185 -0.03470091 -0.4086845  -0.04815823\n",
      "   0.99243137  0.57735027  0.31804249  0.03351712  0.46414283 -0.03247532\n",
      "   0.79003338 -0.17407766  0.57735027  0.22941573 -0.13870227  0.42538498\n",
      "  -0.17407766 -0.57735027  0.          0.22941573  0.          0.23307929\n",
      "   0.90453403 -0.57735027  0.13423121  0.24839254  0.11614359  0.32100769\n",
      "   0.49650487  0.79558708  0.98340899  0.57735027  1.11484672  0.50448368\n",
      "   1.49525651 -1.          0.          1.         -1.          1.\n",
      "  -1.         -0.57735027  0.57735027  0.57735027 -0.30151134  0.71428571\n",
      "  -0.57735027 -0.57735027 -0.33333333  0.68599434 -0.25903681  0.97928752\n",
      "   0.47301616  0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.         -0.57735027 -0.90535746 -0.4068497  -0.82547461 -0.34226778\n",
      "   0.14285714  0.          1.          1.          1.          1.\n",
      "   1.         -0.57735027 -0.57735027  0.57735027 -0.55347007  0.71428571\n",
      "  -0.57735027  0.         -0.11547005 -0.11547005 -0.07832604  0.\n",
      "   0.30151134  0.          0.          0.          0.          0.\n",
      "   0.          0.         -0.81649658 -0.57735027 -0.92331326 -0.57735027\n",
      "  -0.81649658 -0.21647013  0.57735027  0.28746412 -1.37144702  0.72862054\n",
      "  -1.11301811  0.          0.57735027  0.57735027  0.4472136   0.71428571\n",
      "   0.          0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.          0.57735027  0.56790565  0.53078768  0.45434306  0.69838463\n",
      "   0.37707023 -1.          0.30151134  0.70014004  0.70014004  0.06618102\n",
      "  -0.82875156  0.19140249]\n",
      " [ 1.59680207 -0.57735027  1.66003367  1.46714107  1.68282312  1.56564067\n",
      "  -1.57912152 -0.15369466  0.57735027  0.21989975  0.38465747  0.7212524\n",
      "  -0.15369466 -0.57735027  1.67651647  1.50997177  1.70287237  1.59148782\n",
      "  -1.58304416  0.57735027  0.926245    1.23497687  0.67933569  1.36352779\n",
      "  -0.15356867 -0.17407766  0.57735027  0.22941573  0.33684837  0.69404918\n",
      "  -0.17407766 -0.57735027  1.41421356  1.14707867  0.81649658  1.37257804\n",
      "  -1.50755672 -0.57735027  0.          0.14380621 -0.56412599  0.44295474\n",
      "  -1.19887761  0.79558708  0.98340899  0.57735027  0.81488796  0.78218111\n",
      "   0.10432022  1.          0.         -1.          1.         -1.\n",
      "   1.         -0.57735027  0.57735027  0.57735027  0.90453403  1.\n",
      "  -0.57735027 -0.57735027 -1.          0.34299717 -0.86853519  0.89319631\n",
      "  -1.41904849  0.          1.73205081  1.73205081  1.73205081  1.73205081\n",
      "   0.         -0.57735027  1.62964343  1.66438512  0.99296221  1.70347069\n",
      "  -1.          0.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.57735027 -0.57735027  0.57735027 -0.15094638  1.\n",
      "  -0.57735027  0.          0.34641016  0.34641016 -0.07832604  0.81649658\n",
      "  -0.90453403  0.          0.          0.          0.          0.\n",
      "   0.          0.         -0.81649658 -0.57735027 -0.92331326 -0.57735027\n",
      "  -0.81649658 -0.02784639  0.57735027  0.1303577  -0.02713434  0.80274509\n",
      "  -0.86935668  0.          0.57735027  0.57735027  1.34164079  1.\n",
      "   0.          0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.          0.57735027  0.56790565  0.53078768  0.53929106  0.98467894\n",
      "   0.37707023 -1.          1.50755672  1.26025208  1.26025208  1.57114929\n",
      "  -0.98169573 -0.19686112]\n",
      " [ 0.10028226 -0.57735027 -0.41500842 -0.12510505 -0.35221879 -0.37723311\n",
      "   0.72554232 -1.1783257   0.57735027  1.09949874 -1.47547716  0.44956988\n",
      "  -1.1783257  -0.57735027 -0.44947229 -0.1761334  -0.42830002 -0.40158766\n",
      "   0.70435372  0.57735027  0.44246733  0.27930931  0.5835319   0.12627139\n",
      "   0.93670196 -1.21854359  0.57735027  1.14707867 -1.48609575  0.60449444\n",
      "  -1.21854359 -0.57735027  0.          0.22941573  0.81649658 -0.18128389\n",
      "   0.90453403 -0.57735027  1.34231211  1.18966954  1.55964243  0.9235696\n",
      "   1.36841586 -1.65237317 -0.72686751  0.57735027 -1.3048206   0.43043103\n",
      "  -1.28661606 -1.          0.          1.         -1.          1.\n",
      "  -1.         -0.57735027  0.57735027  0.57735027 -1.50755672 -0.14285714\n",
      "  -0.57735027 -0.57735027 -0.33333333  0.68599434 -0.563786   -0.44121746\n",
      "  -0.33786869  0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.         -0.57735027 -0.72428597 -0.25890435 -1.16044981 -0.51536873\n",
      "  -0.71428571  0.          1.          1.          1.          1.\n",
      "   1.         -0.57735027 -0.57735027  0.57735027 -0.95599375 -0.14285714\n",
      "  -0.57735027  0.          1.27017059  1.27017059  1.48819485  0.81649658\n",
      "   1.50755672  0.          0.          0.          0.          0.\n",
      "   0.         -1.41421356  1.63299316  1.73205081  1.46643871  1.73205081\n",
      "   1.63299316 -1.27829167  0.57735027  1.17186491 -0.05581921  0.14320994\n",
      "   0.84887651  0.          0.57735027  0.57735027 -0.4472136  -0.14285714\n",
      "   0.          0.          1.73205081  1.73205081  1.73205081  1.73205081\n",
      "   0.          0.57735027  0.59612457  0.66776515  0.7297805  -0.09109365\n",
      "   0.93275268  1.         -0.90453403 -0.98019606 -0.98019606 -0.51314534\n",
      "   0.30915961  1.40354977]\n",
      " [-0.84082814  1.73205081 -1.00787758 -1.3534092  -0.9470772  -1.18594199\n",
      "  -0.12803688  1.58817811 -1.73205081 -1.62725814  1.28027785 -1.72389028\n",
      "   1.58817811  1.73205081 -0.95590234 -1.29913746 -0.86588785 -1.14174194\n",
      "  -0.11374092 -1.73205081 -1.68675482 -1.5478033  -1.72701042 -1.45732387\n",
      "  -1.57316667  1.5666989  -1.73205081 -1.60591014  1.28794965 -1.7239286\n",
      "   1.5666989   1.73205081 -1.41421356 -1.60591014 -1.63299316 -1.42437344\n",
      "  -0.30151134  1.73205081 -1.47654332 -1.58186829 -1.11166003 -1.68753203\n",
      "  -0.66604312  0.06119901 -1.23995046 -1.73205081 -0.62491408 -1.71709582\n",
      "  -0.31296066  1.          0.         -1.          1.         -1.\n",
      "   1.          1.73205081 -1.73205081 -1.73205081  0.90453403 -1.57142857\n",
      "   1.73205081  1.73205081  1.66666667 -1.71498585  1.691358   -1.43126638\n",
      "   1.28390102  0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.          1.73205081  0.         -0.99863107  0.99296221 -0.84583418\n",
      "   1.57142857  0.         -1.         -1.         -1.         -1.\n",
      "  -1.          1.73205081  1.73205081 -1.73205081  1.6604102  -1.57142857\n",
      "   1.73205081  0.         -1.5011107  -1.5011107  -1.33154276 -1.63299316\n",
      "  -0.90453403  0.          0.          0.          0.          0.\n",
      "   0.          1.41421356  0.         -0.57735027  0.38018781 -0.57735027\n",
      "   0.          1.52260818 -1.73205081 -1.58968672  1.45440057 -1.67457557\n",
      "   1.13349827  0.         -1.73205081 -1.73205081 -1.34164079 -1.57142857\n",
      "   0.          0.         -0.57735027 -0.57735027 -0.57735027 -0.57735027\n",
      "   0.         -1.73205081 -1.73193587 -1.72934051 -1.72341462 -1.59196992\n",
      "  -1.68689315  1.         -0.90453403 -0.98019606 -0.98019606 -1.12418497\n",
      "   1.50128768 -1.39809114]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "print(\"test standardized is\",X_test_standardized,\"train standardized is\",X_train_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R-squared: [-0.8067485]\n",
      "Lasso Regression R-squared: -0.7758675145187031\n",
      "Ridge Regression R-squared: [-0.79070042]\n"
     ]
    }
   ],
   "source": [
    "from json import dump, load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "X = read_csv('features-bulk.csv')\n",
    "y = read_csv('target-bulk.csv')\n",
    "y['K_VRH'] = pd.to_numeric(y['K_VRH'], errors='coerce')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    \n",
    "    #Calculate the R-squared score.\n",
    "    mean_y_true = sum(y_true) / len(y_true)\n",
    "    total_sum_squares = sum((y_i - mean_y_true) ** 2 for y_i in y_true)\n",
    "    # Check if total_sum_squares is zero\n",
    "    if total_sum_squares == 0:\n",
    "        r2 = 0  # or set to another appropriate value\n",
    "    else:\n",
    "        residual_sum_squares = sum((y_i - y_pred_i) ** 2 for y_i, y_pred_i in zip(y_true, y_pred))\n",
    "        r2 = 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "    return r2\n",
    "\n",
    "# Example usage for Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_standardized, y_train)\n",
    "linear_pred_X = linear_model.predict(X_test_standardized)\n",
    "y_true = y_test['K_VRH']\n",
    "y_pred = linear_model.predict(X_train_standardized)\n",
    "linear_r2 = calculate_r2(y_true, y_pred)\n",
    "print(\"Linear Regression R-squared:\", linear_r2)\n",
    "\n",
    "# Example usage for Lasso Regression\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10]}\n",
    "lasso_grid = GridSearchCV(Lasso(max_iter=100000), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train_standardized, y_train)\n",
    "lasso_pred_X = lasso_grid.predict(X_test_standardized)\n",
    "lasso_y_pred = lasso_grid.predict(X_train_standardized)\n",
    "lasso_r2 = calculate_r2(y_true, lasso_y_pred)\n",
    "print(\"Lasso Regression R-squared:\", lasso_r2)\n",
    "\n",
    "# Example usage for Ridge Regression\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10]}\n",
    "ridge_grid = GridSearchCV(Ridge(max_iter=100000), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train_standardized, y_train)\n",
    "ridge_pred_X = ridge_grid.predict(X_test_standardized)\n",
    "ridge_y_pred = ridge_grid.predict(X_train_standardized)\n",
    "ridge_r2 = calculate_r2(y_true, ridge_y_pred)\n",
    "print(\"Ridge Regression R-squared:\", ridge_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso_important_features Index(['MagpieData mean Number', 'MagpieData mean MeltingT',\n",
      "       'MagpieData mean CovalentRadius', 'MagpieData mean NfValence',\n",
      "       'MagpieData mean NValence', 'MagpieData minimum GSvolume_pa',\n",
      "       'MagpieData mean GSvolume_pa', 'MagpieData mean GSmagmom', 'density',\n",
      "       'packing fraction'],\n",
      "      dtype='object')\n",
      "ridge_important_features Index(['MagpieData maximum Number', 'MagpieData mean Number',\n",
      "       'MagpieData avg_dev Number', 'MagpieData maximum AtomicWeight',\n",
      "       'MagpieData mean AtomicWeight', 'MagpieData avg_dev AtomicWeight',\n",
      "       'MagpieData mean Row', 'MagpieData mean CovalentRadius',\n",
      "       'MagpieData mean NpValence', 'density'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lasso_selector = SelectFromModel(lasso_grid.best_estimator_, max_features=10)\n",
    "lasso_selector.fit(X_train_standardized, y_train)\n",
    "ridge_selector = SelectFromModel(ridge_grid.best_estimator_, max_features=10)\n",
    "ridge_selector.fit(X_train_standardized, y_train)\n",
    "lasso_important_features = X.columns[lasso_selector.get_support()]\n",
    "print(\"lasso_important_features\",lasso_important_features)\n",
    "ridge_important_features = X.columns[ridge_selector.get_support()]\n",
    "print(\"ridge_important_features\",ridge_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_poly_train: (944, 10011)\n",
      "Shape of X_poly_test: (237, 10011)\n",
      "(1181, 140)\n"
     ]
    }
   ],
   "source": [
    "# Apply polynomial transformation to the standardized features\n",
    "poly_order = 2\n",
    "poly = PolynomialFeatures(degree=poly_order)\n",
    "X_poly_train = poly.fit_transform(X_train_standardized)\n",
    "X_poly_test = poly.fit_transform(X_test_standardized)\n",
    "#print(X_poly_test,X_poly_train)\n",
    "print(\"Shape of X_poly_train:\", X_poly_train.shape)\n",
    "print(\"Shape of X_poly_test:\", X_poly_test.shape)\n",
    "a = read_csv('features-bulk.csv')\n",
    "print(a.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=Lasso(max_iter=100000),\n",
      "             param_grid={'alpha': [0.01, 0.1, 1, 10]})\n"
     ]
    }
   ],
   "source": [
    "# Fit Lasso regression on the polynomial features\n",
    "lasso_grid_poly = GridSearchCV(Lasso(max_iter=100000), lasso_params, cv=5)\n",
    "lasso_grid_poly.fit(X_poly_train, y_train)\n",
    "print(lasso_grid_poly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features based on the best estimator:\n",
      "(944, 10)\n"
     ]
    }
   ],
   "source": [
    "# Perform feature selection on the polynomial features\n",
    "lasso_selector_poly = SelectFromModel(lasso_grid_poly.best_estimator_, max_features=10)\n",
    "lasso_selector_poly.fit(X_poly_train, y_train)\n",
    "#print(lasso_selector_poly)\n",
    "\n",
    "selected_features_mask = lasso_selector_poly.get_support()\n",
    "selected_features = X_poly_train[:, selected_features_mask]\n",
    "\n",
    "print(\"Selected features based on the best estimator:\")\n",
    "print(selected_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' 'space_group' 'MagpieData minimum Number' ... 'vpa^2'\n",
      " 'vpa packing fraction' 'packing fraction^2']\n",
      "selected_features_indices_poly_str ['23', '110', '138', '139', '3106', '5638', '9064', '9709', '9710', '10008']\n",
      "selected_features_indices_original [23, 110, 138, 139, 3106, 5638, 9064, 9709, 9710, 10008]\n",
      "Cubic_lasso_important_features ['MagpieData mean MeltingT' 'MagpieData minimum GSvolume_pa' 'density'\n",
      " 'vpa' 'MagpieData mean MeltingT vpa'\n",
      " 'MagpieData mean Electronegativity vpa'\n",
      " 'MagpieData mode NdUnfilled packing fraction'\n",
      " 'MagpieData minimum GSbandgap vpa'\n",
      " 'MagpieData minimum GSbandgap packing fraction' 'vpa^2']\n"
     ]
    }
   ],
   "source": [
    "selected_features_indices_poly = lasso_selector_poly.get_support(indices=True)\n",
    "\n",
    "# Get the feature names after polynomial transformation\n",
    "poly_feature_names = poly.get_feature_names_out(X.columns)\n",
    "print(poly_feature_names)\n",
    "\n",
    "# Convert feature indices to strings for comparison\n",
    "selected_features_indices_poly_str = [str(i) for i in selected_features_indices_poly]\n",
    "print(\"selected_features_indices_poly_str\", selected_features_indices_poly_str)\n",
    "\n",
    "# Map the selected feature indices back to the original feature names\n",
    "selected_features_indices_original = [int(x) for x in selected_features_indices_poly_str if int(x) < len(poly_feature_names)]\n",
    "print(\"selected_features_indices_original\", selected_features_indices_original)\n",
    "\n",
    "# Extract the corresponding feature names\n",
    "cubic_lasso_important_features = np.array(poly_feature_names[selected_features_indices_original]).flatten()\n",
    "\n",
    "# Print the important features\n",
    "print(\"Cubic_lasso_important_features\", cubic_lasso_important_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task 2.4: Tree Regressors\n",
    "Train a decision tree regressor and choose the optimal tree depth. Additionally, select one of the methods to modify a decision tree (Adaboost, Gradient Boost, Hist-Boost). Store the ten most important features. Explain the modification method that you chose in the theory section. Decision trees have a feature importance feature. Explain it (roughly) in the theory section. Do not fit the tree regressors to the polynomially expanded features as it will take forever and regression trees are already nonlinear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.4.1: Train Decision Tree Regressor\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Find optimal tree depth using GridSearchCV\n",
    "param_grid = {'max_depth': np.arange(1, 21)}\n",
    "grid_search_tree = GridSearchCV(tree_reg, param_grid, cv=5, scoring='r2')\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "optimal_tree_depth = grid_search_tree.best_params_['max_depth']\n",
    "\n",
    "# Train the Decision Tree Regressor with the optimal depth\n",
    "final_tree_reg = DecisionTreeRegressor(max_depth=optimal_tree_depth, random_state=42)\n",
    "final_tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Task 2.4.2: Train Gradient Boosted Decision Tree\n",
    "gradient_boost_reg = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Find optimal parameters using GridSearchCV\n",
    "param_grid_gb = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "grid_search_gb = GridSearchCV(gradient_boost_reg, param_grid_gb, cv=5, scoring='r2')\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "optimal_n_estimators = grid_search_gb.best_params_['n_estimators']\n",
    "optimal_learning_rate = grid_search_gb.best_params_['learning_rate']\n",
    "\n",
    "# Train the Gradient Boosted Decision Tree with optimal parameters\n",
    "final_gb_reg = GradientBoostingRegressor(n_estimators=optimal_n_estimators, learning_rate=optimal_learning_rate, random_state=42)\n",
    "final_gb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Store the ten most important features for both models\n",
    "tree_importances = final_tree_reg.feature_importances_\n",
    "gb_importances = final_gb_reg.feature_importances_\n",
    "\n",
    "top_10_tree_features = np.argsort(tree_importances)[-10:][::-1]\n",
    "top_10_gb_features = np.argsort(gb_importances)[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.86966354e-03 7.27162520e-05 2.30811365e-05 3.19098792e-04\n",
      " 2.68797811e-04 2.46202613e-04 5.95983222e-06 1.25016712e-02\n",
      " 9.48533941e-05 6.29700390e-04 3.15636020e-03 3.70357493e-03\n",
      " 7.79111607e-04 2.80653698e-05 5.12549760e-04 6.58992558e-04\n",
      " 4.04628972e-04 1.63137537e-03 4.35980387e-04 8.80984507e-02\n",
      " 2.43791035e-02 1.63754764e-03 5.49126500e-01 1.68671114e-03\n",
      " 5.18507904e-03 1.61468826e-06 6.19693974e-05 1.31447794e-08\n",
      " 4.02832221e-04 1.05832814e-03 6.12270513e-03 3.40223480e-05\n",
      " 1.24449378e-06 1.74970065e-04 4.03579402e-04 3.77780809e-04\n",
      " 4.65975540e-05 1.48183631e-04 6.42248412e-04 1.95994088e-04\n",
      " 4.94365135e-03 2.91584555e-04 1.31223493e-05 2.34121795e-04\n",
      " 2.86203792e-03 2.46657399e-04 1.95008430e-02 1.30460494e-03\n",
      " 1.39467414e-04 5.31797438e-05 1.10123395e-04 1.08283735e-06\n",
      " 5.80175548e-04 7.08715735e-04 8.70693404e-08 0.00000000e+00\n",
      " 1.85511410e-06 1.05560733e-06 2.78596239e-06 1.01563131e-04\n",
      " 1.71703201e-06 1.73702216e-05 7.23813574e-06 1.02434777e-04\n",
      " 6.70319483e-04 1.20293740e-03 2.62200897e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.62566685e-04 5.12872893e-04\n",
      " 0.00000000e+00 1.02193806e-04 1.06183796e-05 1.70387634e-04\n",
      " 4.80490984e-04 4.01141129e-03 2.41701419e-02 0.00000000e+00\n",
      " 3.26193012e-06 9.19123775e-05 9.17598267e-07 5.93940295e-04\n",
      " 4.56599628e-05 0.00000000e+00 5.03690423e-06 4.05645952e-06\n",
      " 2.89121646e-05 4.92336648e-06 2.50544861e-05 1.15502184e-08\n",
      " 4.00351573e-05 7.73567448e-05 1.83850741e-03 2.09629995e-03\n",
      " 2.86023798e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.56981369e-05\n",
      " 3.83812417e-05 5.87984278e-05 5.14417489e-03 1.23391978e-03\n",
      " 5.55660479e-03 6.29390142e-04 3.59092864e-02 9.78561877e-04\n",
      " 8.11395671e-04 1.02073597e-03 1.39021137e-02 0.00000000e+00\n",
      " 9.16673250e-05 0.00000000e+00 3.86321400e-04 1.96787300e-04\n",
      " 0.00000000e+00 0.00000000e+00 1.30036101e-03 1.34805963e-06\n",
      " 7.26658144e-04 8.60565513e-05 0.00000000e+00 4.04816953e-05\n",
      " 2.49141032e-03 4.11305085e-05 1.27569633e-03 1.94813611e-03\n",
      " 3.67692217e-07 3.61738775e-04 7.67178034e-06 1.20112440e-04\n",
      " 1.15822334e-03 7.33185020e-03 1.19443386e-01 1.95955130e-02]\n"
     ]
    }
   ],
   "source": [
    "print(tree_importances )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important_features based on DecisionTreeRegressor Index(['MagpieData mean MeltingT', 'vpa', 'MagpieData minimum MeltingT',\n",
      "       'MagpieData maximum GSvolume_pa', 'MagpieData maximum MeltingT',\n",
      "       'MagpieData mode NValence', 'packing fraction',\n",
      "       'MagpieData mean Electronegativity', 'MagpieData mode GSvolume_pa',\n",
      "       'MagpieData minimum MendeleevNumber'],\n",
      "      dtype='object') important_features based on GradientBoostingRegressor Index(['MagpieData mean MeltingT', 'vpa', 'density',\n",
      "       'MagpieData minimum MeltingT', 'MagpieData maximum MeltingT',\n",
      "       'MagpieData minimum Column', 'MagpieData mode Column',\n",
      "       'MagpieData mode GSvolume_pa', 'MagpieData maximum GSvolume_pa',\n",
      "       'MagpieData mean GSvolume_pa'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"important_features based on DecisionTreeRegressor\",X.columns[top_10_tree_features], \"important_features based on GradientBoostingRegressor\",X.columns[top_10_gb_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal regularization parameter = 10\n",
      "optimal kernel is poly\n",
      "optimal gamma = 0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KernelRidge(alpha=10, gamma=0.1, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KernelRidge</label><div class=\"sk-toggleable__content\"><pre>KernelRidge(alpha=10, gamma=0.1, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KernelRidge(alpha=10, gamma=0.1, kernel='poly')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_kernel = {'alpha': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# Create a Kernel Ridge Regressor\n",
    "kernel_ridge = KernelRidge()\n",
    "\n",
    "# Perform GridSearchCV to find optimal parameters\n",
    "grid_search_kernel = GridSearchCV(kernel_ridge, param_grid_kernel, cv=5, scoring='r2')\n",
    "grid_search_kernel.fit(X_train_standardized, y_train)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "optimal_alpha = grid_search_kernel.best_params_['alpha']\n",
    "optimal_kernel = grid_search_kernel.best_params_['kernel']\n",
    "optimal_gamma = grid_search_kernel.best_params_['gamma']\n",
    "\n",
    "print(\"optimal regularization parameter =\",optimal_alpha)\n",
    "print(\"optimal kernel is\",optimal_kernel)\n",
    "print(\"optimal gamma =\",optimal_gamma)\n",
    "\n",
    "'''final_kernel_reg = KernelRidge(alpha=optimal_alpha, kernel=optimal_kernel, gamma=optimal_gamma)\n",
    "final_kernel_reg.fit(X_train_standardized, y_train)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
